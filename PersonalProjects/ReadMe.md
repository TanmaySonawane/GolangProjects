The first project is WebScraper. It takes a file with 1 million websites on it and uses worker pool with 100 workers, meaning it concurrently visits 
100 websites at the same time, bringing down the execution time. 
